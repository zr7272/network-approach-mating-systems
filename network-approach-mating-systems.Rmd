---
title: "A complex systems approach to study animal mating systems"
author: "Zita Roithmair & Dion O'Neale"
output: html_document
---

This notebook demonstrates how we can construct a bipartite species-trait network
and analyse it to find trait associations that resemble "mating system syndromes" that are candidates for being 
associated with mating systems.

We use data for a collection of 12 spider species and 44 associated behavioural, ecological and life history traits, both on the individual and population level. 

# Preamble
```{r preamble}
#Load some packages.
#Some are common; a couple will likely need to be installed from source
library(tidyverse)
library(igraph)
library(archnetan)
library(tidygraph)
library(ggraph)
```

# Load data. Draw a network
Input data is stored as a csv with two columns: species and traits that they are 
associated with. The function `create_graph_single_file` loads in two labeled columns 
from the csv and creates a bipartite graph with each column corresponding to a 
node type (either species or trait) and each row corresponding to an edge between the named vertices.
```{r load data}

spider_trait_network <- create_graph_single_file(("spider-trait.csv"), "species", "trait")

#plot with igraph
plot(spider_trait_network$graph, 
     layout = layout_as_bipartite(spider_trait_network$graph)[,2:1],
     vertex.label.dist = 3.7,
     vertex.label.cex=0.45,
     vertex.label.degree=pi*V(spider_trait_network$graph)$type,
     edge.width=1,
     vertex.size=5
     )

```


# Project onto the trait nodes using cosine similarity
Here we create a one-mode network by projecting the species-trait network on to 
the traits. We do this using cosine similarity where each trait is associated 
with a vector of species that posses that trait. For each pair of traits, we 
calculate how similar they are, in terms of the sets of species that they co-occur 
in. The similarity is quantified by taking the cosine of the angle between the 
pair of species vectors. Values close to one indicate traits that co-occur for the 
same sets of species; values close to zero indicate that the traits occur for 
mutually exclusive sets of species.

The code also calculates the projection onto species (again using cosine similarity)
at the same time. We don't use that information here.
```{r project on to traits}

#calculate cosine similarities in both directions
similarity <- calc_cos_sim(spider_trait_network$df)

#pull out the values for the trait network
trait_sim <- similarity$col2_cossim %>% # col2 is traits
  rename(from = p1,
         to = p2,
         weight = sim) %>%
  filter(weight > 0) #remove edges with weight == 0

#plot the graph - it is not very informative at this stage.
trait_sim_graph <- graph_from_data_frame(trait_sim, directed = FALSE)
plot(trait_sim_graph,
     layout = layout_with_fr(trait_sim_graph, 
                             weights = trait_sim_graph$weight),
     vertex.label.dist = 3.7,
     vertex.label.cex=0.45,
     edge.width=trait_sim_graph$weight,
     vertex.size=5
     )

#plot a couple of frequency histograms of the edge weights too, for sense checking
ggplot(trait_sim, aes(weight)) + geom_histogram(bins = 100)
ggplot(trait_sim, aes(weight)) + geom_histogram(bins = 10)

```

# Apply community detection to the trait network

```{r community detection}

#apply louvain community detection
trait_communities_louvain <- cluster_louvain(trait_sim_graph) # note - this is one option for a community detection algorithm (see other options below). Occasionally the same algorithm will assign the same trait to different communities, so it makes sense to test the robistness of the community detection before interpreting results (see further below). Some algorithms will be more consistent than others.

#Examples of other community detection options:

#fast-greedy community detection
#walktrap community detection
#modularity optimization community detection

#plotting the results

#Note - to visualise communities better it helps to either manually arrange the vertices or create a community-dependent layout

V(trait_sim_graph)$community <- trait_communities_louvain$membership

spread_layout <- layout_nicely(trait_sim_graph)

#community1
spread_layout[,2] <- spread_layout[,2] + ifelse(V(trait_sim_graph)$community == 1, 2.3, 0)
spread_layout[,1] <- spread_layout[,1] + ifelse(V(trait_sim_graph)$community == 1, 2.3, 0)
#community2
spread_layout[,2] <- spread_layout[,2] + ifelse(V(trait_sim_graph)$community == 2, 1.5, 0)
spread_layout[,1] <- spread_layout[,1] + ifelse(V(trait_sim_graph)$community == 2, -2.3, 0)
#community3
spread_layout[,2] <- spread_layout[,2] + ifelse(V(trait_sim_graph)$community == 3, -2.3, 0)
spread_layout[,1] <- spread_layout[,1] + ifelse(V(trait_sim_graph)$community == 3, 2.3, 0)
#community4
spread_layout[,2] <- spread_layout[,2] + ifelse(V(trait_sim_graph)$community == 4, -2.3, 0)
spread_layout[,1] <- spread_layout[,1] + ifelse(V(trait_sim_graph)$community == 4, -2.3, 0)

plot(trait_communities_louvain,
     trait_sim_graph,
     layout = spread_layout,
     vertex.size = degree(trait_sim_graph)*0.5,
     vertex.label.cex = 0.5,
     vertex.label.color = "black",
     edge.width = E(trait_sim_graph)$weight*3,
     edge.color = adjustcolor("grey50", alpha.f = 0.5)
)


```


# A function for testing robustness of data via bootstrapping
We'd like to test how robust our results are to perturbation of the initial data. I.e. if a row or two was missing from our original data, how much would our findings with respect to communities differ by?
```{r perturbated data robustness}

# the following loop throws out single species-trait observations (= rows) of the original data set and compares the resulting communities

# define communitry detection function

get_t_communities <- function(df) {
  sim_matrix <- calc_cos_sim(df)
  trait_sim_matrix <- sim_matrix$col2_cossim
  colnames(trait_sim_matrix) <- c("from", "to", "weight")
  trait_sim_matrix <- subset(trait_sim_matrix, weight > 0)
  trait_com <- calc_com_louv(trait_sim_matrix)
  return(trait_com)
}


# set parameters

N = 173                                                      # how many possible iterations (= rows of dataset)
deg = degree(trait_sim_graph)                                # degree of original (full data graph)
membership_original <- membership(trait_communities_louvain)                        # community membership per trait of original
membership_original_nr <- as.numeric(membership_original)    # as numeric
nmi = ari = num = ham = spe = numeric(N)                     # specify form of output
membermatrix = matrix(0, 44, 173)                            # prepare matrix for output
rownames(membermatrix) <- as.vector(V(trait_sim_graph)$name)         # add traits as row names
trait_names=trait_communities_louvain$names                                         # extracting trait names in correct order

# run loop

pb = txtProgressBar(min = 0, max = N, style = 3)                        # set process bar
for (i in 1:N) {                                                        # loop for all rows (= N)
  df_mod = spider_trait_network$df[-i, ]                                        # remove 1 observation from data frame
  trait_com = get_t_communities(df_mod)                                 # calculate similarity matrix + apply community detection to modified graph/dataframe
  mem = membership(trait_com$community)                                 # get community memberships
  mem_o = setNames(rep(0,times=length(trait_names)),trait_names)        # create empty vector with all 44 trait names
  for(j in 1:length(trait_names)) {                                     # another loop for traits
    p=trait_names[j]                                                    # call each trait according to the original dataset
    if(is.na(mem[p])==T) {                                              # check if trait is NA
      mem_o[p]=0                                                        # if trait is NA -> replace with 0
    } else {
      mem_o[p]=mem[p]                                                   # if trait is not NA -> leave it as it is
    }
  } 
  memb = as.numeric(mem_o)                                              # as numeric
  membermatrix[,i] = memb                                               # stores output into matrix
  nmi[i] = aricode::NMI(membership_original_nr, memb)                   # calculate "Normalised mutual information"
  ari[i] = aricode::ARI(membership_original_nr, memb)                   # calculate "Adjusted Rand index"
  num[i] = length(unique(memb))                                         # calculate how many clusters
  deg2 = degree(trait_com$G)                                            # calculate degree of "new" graph
  deg_o = setNames(rep(NA,times=length(trait_names)),trait_names)       # create empty vector with all 44 trait names
  for (k in 1:length(trait_names)) {                                    # another loop for traits
    q=trait_names[k]                                                    # call each trait according to the original dataset
    deg_o[q]=deg2[q]                                                    # assign degree for each trait to trait-name-vector
  } 
  spe[i] = cor(deg, deg_o)                                              # calculate "Spearman's correlation"
  setTxtProgressBar(pb, i)                                              # progress bar +1
}
close(pb)

# plot the results

hist(nmi, 30, main="Normalised mutual information", prob=TRUE, xlab="")
hist(ari, 30, main="Adjusted Rand index", prob=TRUE, xlab="")
hist(num, 30, main="Number of clusters", xlab="")
hist(spe, 30, main="Spearman's correlation", prob=TRUE, xlab="")


```

#Community detection robustness
Given a single instance of initial data and a single community detection method, 
we would like to quantify how consistently the clustering algorithm returns the same 
community membership vector.
To do this we'll run the community detection process a number of times and store 
the membership information. We'll then do pairwise comparisons between all the 
membership results and plot the distibution of some suitable metric.
(Currently NMI or adjusted RAND index, but could easily be changed).
```{r community detection robustness}
#get communities several times, using the same input data,
#then see how similar they are.

#function that returns a "community" class object as per the igraph docs
get_communities <- function(df) {
# given a dataframe that represents a bipartite network, calculate the cosine similarity and apply a clustering method.
# return the community memberships
  communities <- calc_cos_sim(df)$col2_cossim %>%
    rename(from = p1,
           to = p2,
           weight = sim) %>%
    filter(weight > 0) %>%
    graph_from_data_frame(directed = FALSE) %>%
    cluster_louvain() # currently the clustering method is hard coded. Would be nice to make this an optional input to the function
  return(communities)
}

N <- 100 #number of times to find communities

#empty list to store communities classes
com_list <- list()

#run N times
for (i in 1:N){
  com_list[[i]] <- get_communities(spider_trait_network$df)
}

#empty df for storing pairwise comparisons
comparisons_df <- data.frame(i=integer(),
                             j=integer(),
                             adjusted_rand=double(),
                             nmi=double()
                             )

#do pair-wise comparisons of communities
for (i in 1:(N-1)){
  for (j in (i+1):N) {
    results <- data.frame(i=i,
                          j=j,
                          adjusted_rand = compare(com_list[[i]], com_list[[j]], method = 'adjusted.rand'),
                          nmi = compare(com_list[[i]], com_list[[j]], method = 'nmi')
                 )
    comparisons_df <- comparisons_df %>% add_row(results)
  }
}

ggplot(comparisons_df, aes(adjusted_rand)) + geom_histogram(bins = 20)
  



```
